---
title: "StateSpacePondTempModel - YF"
author: "Amaryllis Adey"
date: "`r Sys.Date()`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Exploring the state-space model framework using code based on 'Activity 6 - State-space models' that Alyssa shared along

# Set up the working space for the analysis

## Load in packages

```{r}
library(rjags)
library(daymetr)
library(ecoforecastR)
library(dplyr)
library(lubridate)
library(zoo)
library(ggplot2)
```

## Start by loading in the Yakutat Forelands mean data set

```{r}
YF_Temps <- read.csv("YF_PondAirTemp_mean.csv", header=TRUE)

YF_Temps <- YF_Temps %>%
  rename(`Month-Year` = Month.Year) %>%
  select(-c(1))
```

## Separate the data into the air temp and the water temp data

```{r}
YF_AirTemp <- YF_Temps %>%
  select(`Month-Year`, Airport, Air_MonthAvg, Region)

YF_WaterTemp <- YF_Temps %>%
  select(`Month-Year`, MP1, MP3, PL3, PL2, UBP3, MP5, MP8, UBP1, UBP2, PL1, UBP4)
```

# Starting the Analysis

## Part 1 - Model with only the water temperature in it

### Pull in the data we want to analyze

Here this is set up as just one pond and temperature data

```{r}
YF_WaterTemp

# pulling out the dates here
time <- as.Date(YF_WaterTemp$`Month-Year`, "%m-%Y")

# Choose one pond to plot through time -- MP1
y = YF_WaterTemp %>%
  select(MP1)
y

```

The code itself has three components, the data model, the process model, and the priors.

Data Model - relates the observed data, y, at any time point to the latent variable, x. For this example we'll assume that the observation model just consists of Gaussian observation error.

Process Model - relates the state of the system at one point in time to the state one time step ahead. In this case we'll start with the simplest possible process model, a random walk, which just consists of Gaussian process error centered around the current value of the system.

Priors - Finally, for the priors we need to define **priors** for the initial condition, the process error, and the observation error.

### Setting up the random walk

```{r}
RandomWalk = "
model{
  
  #### Data Model
  for(t in 1:n){
    y[t] ~ dnorm(x[t],tau_obs)
  }
  
  #### Process Model
  for(t in 2:n){
    x[t]~dnorm(x[t-1],tau_add)
  }
  
  #### Priors
  x[1] ~ dnorm(x_ic,tau_ic)
  tau_obs ~ dgamma(a_obs,r_obs)
  tau_add ~ dgamma(a_add,r_add)
}
"
```

### Next we need to define the data and priors as a list.

```{r}
data <- list(y=y$MP1,n=length(y),     ## data
             x_ic=1,tau_ic=1,           ## initial condition prior
             a_obs=1,r_obs=1,           ## obs error prior
             a_add=1,r_add=1            ## process error prior
             )
```

### Next we need to definite the initial state of the model's parameters for each chain in the MCMC. The overall initialization is stored as a list the same length as the number of chains, where each chain is passed a list of the initial values for each parameter. Unlike the definition of the priors, which had to be done independent of the data, the initialization of the MCMC is allowed (and even encouraged) to use the data. However, each chain should be started from different initial conditions. We handle this below by basing the initial conditions for each chain off of a different random sample of the original data.

AW - take for each pond and have what was originally here with a sample from each pond and take a sample. Then average across ponds for each of these values. Also will indicate the importance between ponds by comparing this versus the average among ponds

```{r}
nchain = 3
init <- list()
for(i in 1:nchain){
  vect <- c(y$MP1)
  y.samp = sample(vect,length(vect),replace=TRUE)
  init[[i]] <- list(tau_add=1/var(diff(y.samp)),  ## initial guess on process precision
                    tau_obs=5/var(y.samp))        ## initial guess on obs precision
}
```

### Now that we've defined the model, the data, and the initialization, we need to send all this info to JAGS, which will return the JAGS model object.

```{r}
j.model   <- jags.model (file = textConnection(RandomWalk),
                             data = data,
                             inits = init,
                             n.chains = 3)
```

### Next, given the defined JAGS model, we'll want to take a few samples from the MCMC chain and assess when the model has converged. To take samples from the MCMC object we'll need to tell JAGS what variables to track and how many samples to take.

```{r, fig.asp = 1.0}
## burn-in
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("tau_add","tau_obs"),
                                n.iter = 1000)
plot(jags.out)
```

### Since rjags returns the samples as a CODA object, we can use any of the diagnostics in the R *coda* library to test for convergence, summarize the output, or visualize the chains.

Now that the model has converged we'll want to take a much larger sample from the MCMC and include the full vector of X's in the output

```{r}
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("x","tau_add","tau_obs"),
                                n.iter = 10000)
```

### Given the full joint posterior samples, we're next going to visualize the output by just looking at the **95% credible interval of the time-series of X's** and compare that to the observed Y's. To do so we'll convert the coda output into a matrix and then calculate the quantiles. Looking at colnames(out) will show you that the first two columns are `tau_add` and `tau_obs`, so we calculate the CI starting from the 3rd column. We also transform the samples back from the log domain to the linear domain.

```{r}
## THIS CHUNK OF CODE DOES NOT WORK CORRECTLY -- USED CODE BELOW INSTEAD
time.rng = c(1,length(time))       ## adjust to zoom in and out
out <- as.matrix(jags.out)         ## convert from coda to matrix  
x.cols <- grep("^x",colnames(out)) ## grab all columns that start with the letter x
ci <- apply(out[,x.cols],2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale -- AA think I can skip this since I got rid of the log transformation
ci <- apply(data.frame(out[, x.cols]), 2, quantile, c(0.025, 0.5, 0.975))

plot(time,ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Water Temp",log='y',xlim=time[time.rng])
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightBlue",0.75))
points(time,y,pch="+",cex=0.5)
```
### Plotting a reconstruction of the fitted line to the air temp-water temp data

Do this by looping through each iteraction of the MCMC output, each of which has a value for each parameter in your process equation, and making the fitted points by hand.

```{r}
# THIS CODE IS ADAPTED TO PART 3 BUT CAN BE UPDATED FOR THIS
out <- as.matrix(jags.out)       ## convert from coda to matrix  
N_sim = 10000

# Initialize vectors to store results
x <- numeric(N_sim)
predicted_lake_temp <- numeric(N_sim)
observed_lake_temp <- numeric(N_sim)

# Loop through each row of the output matrix
for(i in 1:N_sim) {
  x[i] <- out[i, "tau_add"] # extract the estimated latent variable at the previous time step
  predicted_lake_temp[i] <- x[i]
}

str(predicted_lake_temp) # this now had a vector for each iteration and then will need to summarize this to make it work for plotting

library(dplyr)
library(purrr)
# Extract the first element from each vector in predicted_lake_temp and calculate the average
average_values <- numeric(73)

# Loop through each position (1 to 73)
for (i in 1:73) {
  # Extract values at position i from all vectors in predicted_lake_temp
  values <- sapply(predicted_lake_temp, `[`, i)
  # Calculate the average for position i
  average_values[i] <- mean(values, na.rm = TRUE)
}

# Plot the average values
plot(average_values, type = "l", col = "blue",
     main = "Average Predicted Lake Temperature",
     xlab = "Time Step", ylab = "Average Temperature")

# Plot each element of predicted_lake_temp
#for (i in 1:length(predicted_lake_temp)) {
#  plot(predicted_lake_temp[[i]], type = "l", col = "blue", ylim = c(-1000, 1000),
#       main = "Predicted Lake Temperature", xlab = "Time Step", ylab = "Temperature")
#}

# Add a legend
#legend("topright", legend = 1:length(predicted_lake_temp), col = "blue", lty = 1, title = "Iteration")

```

### Next, lets look at the posterior distributions for `tau_add` and `tau_obs`, which we'll convert from precisions back into **standard deviations**.

```{r}
hist(1/sqrt(out[,1]),main=colnames(out)[1])
hist(1/sqrt(out[,2]),main=colnames(out)[2])
```

### We'll also want to look at the joint distribution of the two parameters to check whether the two parameters strongly covary.

```{r, fig.asp = 1.0}
plot(out[,1],out[,2],pch=".",xlab=colnames(out)[1],ylab=colnames(out)[2])
cor(out[,1:2])
```

## Part 2 - Adding in more than one pond

```{r}
YF_WaterTemp

# pulling out the dates here
time <- as.Date(YF_WaterTemp$`Month-Year`, "%m-%Y")

# Choose one pond to plot through time -- MP1
y = YF_WaterTemp %>%
  select(MP1, MP3)
```

### Trying to include more of the ponds here instead of just the one like above

```{r}
RandomWalk_all = "
model{
  
  #### Data Model
  for(p in 1:q){
   for(t in 1:n){
      y[t,p] ~ dnorm(x[t,p],tau_obs)
  }
  }
  
  
  #### Process Model
  for(p in 1:q){
   for(t in 2:n){
    x[t,p]~dnorm(x[t-1,p],tau_add)
  }
  }
 
  
  #### Priors
  for(p in 1:q){
  x[1,p] ~ dnorm(x_ic,tau_ic)
  }
  tau_obs ~ dgamma(a_obs,r_obs)
  tau_add ~ dgamma(a_add,r_add)
}
"
```

### Next we need to define the data and priors as a list.

This should be for the RandonWalk_all now

```{r}
data <- list(y=y, n=nrow(y), q=ncol(y),    ## data
             x_ic=0,tau_ic=0.2,
             a_obs=1,r_obs=1,           ## obs error prior
             a_add=1,r_add=1            ## process error prior
             )
```

### Next we need to definite the initial state of the model's parameters for each chain in the MCMC. The overall initialization is stored as a list the same length as the number of chains, where each chain is passed a list of the initial values for each parameter. Unlike the definition of the priors, which had to be done independent of the data, the initialization of the MCMC is allowed (and even encouraged) to use the data. However, each chain should be started from different initial conditions. We handle this below by basing the initial conditions for each chain off of a different random sample of the original data.

AW - take for each pond and have what was originally here with a sample from each pond and take a sample. Then average across ponds for each of these values. Also will indicate the importance between ponds by comparing this versus the average among ponds

```{r}
nchain = 3
init <- list()
for(i in 1:nchain){
  vect <- c(y$MP1, y$MP3)
  y.samp = sample(vect,length(vect),replace=TRUE)
  init[[i]] <- list(tau_add=1/var(diff(y.samp)),  ## initial guess on process precision
                    tau_obs=5/var(y.samp))        ## initial guess on obs precision
}
```

### Now that we've defined the model, the data, and the initialization, we need to send all this info to JAGS, which will return the JAGS model object.

```{r}
j.model   <- jags.model (file = textConnection(RandomWalk_all),
                             data = data,
                             inits = init,
                             n.chains = 3)
```

### Next, given the defined JAGS model, we'll want to take a few samples from the MCMC chain and assess when the model has converged. To take samples from the MCMC object we'll need to tell JAGS what variables to track and how many samples to take.

```{r, fig.asp = 1.0}
## burn-in
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("tau_add","tau_obs"),
                                n.iter = 1000)
plot(jags.out)
```

### Since rjags returns the samples as a CODA object, we can use any of the diagnostics in the R *coda* library to test for convergence, summarize the output, or visualize the chains.

Now that the model has converged we'll want to take a much larger sample from the MCMC and include the full vector of X's in the output

```{r}
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("x","tau_add","tau_obs"),
                                n.iter = 10000)
```

### Given the full joint posterior samples, we're next going to visualize the output by just looking at the **95% credible interval of the time-series of X's** and compare that to the observed Y's. To do so we'll convert the coda output into a matrix and then calculate the quantiles. Looking at colnames(out) will show you that the first two columns are `tau_add` and `tau_obs`, so we calculate the CI starting from the 3rd column. We also transform the samples back from the log domain to the linear domain.

```{r}
time.rng = c(1,length(time))       ## adjust to zoom in and out
out <- as.matrix(jags.out)         ## convert from coda to matrix  
x.cols <- grep("^x",colnames(out)) ## grab all columns that start with the letter x
ci <- apply(exp(out[,x.cols]),2,quantile,c(0.025,0.5,0.975)) ## model was fit on log scale

plot(time,ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Flu Index",log='y',xlim=time[time.rng])
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightBlue",0.75))
points(time,y,pch="+",cex=0.5)
```

### Next, lets look at the posterior distributions for `tau_add` and `tau_obs`, which we'll convert from precisions back into **standard deviations**.

```{r}
hist(1/sqrt(out[,1]),main=colnames(out)[1])
hist(1/sqrt(out[,2]),main=colnames(out)[2])
```

### We'll also want to look at the joint distribution of the two parameters to check whether the two parameters strongly covary.

```{r, fig.asp = 1.0}
plot(out[,1],out[,2],pch=".",xlab=colnames(out)[1],ylab=colnames(out)[2])
cor(out[,1:2])
```

## Part 3 - Back to one pond, but with temperature as a covariate

### Pull in the data we want to analyze

```{r}
YF_WaterTemp

# pulling out the dates here

time <- as.Date(paste0("01-", YF_WaterTemp$`Month-Year`), format = "%d-%m-%Y")

# Choose one pond to plot through time -- MP1
y = YF_WaterTemp %>%
  select(MP1)

temp = YF_AirTemp %>%
  select(Air_MonthAvg)

plotData <- y %>%
  mutate(time = time)

ggplot(data = plotData, aes(x = time, y = MP1))+
  geom_point()+
  theme_bw()
```
## Part 4 Going back to the code from Alyssa

### Setting up the random walk --> added in the air temperature here
 This option adds it so the beta0 and m are separate named variables
```{r}
RandomWalk = "
model{
  
  #### Data Model
  for(t in 1:n){
    y[t] ~ dnorm(x[t],tau_obs)
  }
  
  #### Process Model
  for(t in 2:n){
    x[t]~dnorm(k[t-1],tau_add)
    k[t-1] <- beta0 + m * temp[t-1]
  }
  
  #### Priors
  x[1] ~ dnorm(x_ic,tau_ic)
  tau_obs ~ dgamma(a_obs,r_obs)
  tau_add ~ dgamma(a_add,r_add)
}
"
```

This option sets it up with the matrix of betas
```{r}
RandomWalk_Temp = "
model{
  
  #### Data Model
  for(t in 1:n){
    y[t] ~ dnorm(x[t],tau_obs)
  }
  
  #### Process Model
  for(t in 2:n){
    x[t]~dnorm(k[t],tau_add)
    k[t] <- beta0[1] + beta0[2] * temp[t]
  }
  
  #### Priors
  x[1] ~ dnorm(x_ic,tau_ic)
  beta0 ~ dmnorm(betap, sigmap)
  tau_obs ~ dgamma(a_obs,r_obs)
  tau_add ~ dgamma(a_add,r_add)
}
"
```

### Next we need to define the data and priors as a list. 
```{r}
data <- list(y=y$MP1,n=length(y),     ## data
             x_ic=0,tau_ic=0.2,
             betap=c(0,0), sigmap=diag(0.01, 2, 2),
             temp = temp, ## initial condition prior
             a_obs=1,r_obs=1,           ## obs error prior
             a_add=1,r_add=1            ## process error prior
             )
```

### Next we need to definite the initial state of the model's parameters for each chain in the MCMC. The overall initialization is stored as a list the same length as the number of chains, where each chain is passed a list of the initial values for each parameter. Unlike the definition of the priors, which had to be done independent of the data, the initialization of the MCMC is allowed (and even encouraged) to use the data. However, each chain should be started from different initial conditions. We handle this below by basing the initial conditions for each chain off of a different random sample of the original data.

AW - take for each pond and have what was originally here with a sample from each pond and take a sample. Then average across ponds for each of these values. Also will indicate the importance between ponds by comparing this versus the average among ponds

```{r}
nchain = 3
init <- list()
for(i in 1:nchain){
  vect <- c(y$MP1)
  y.samp = sample(vect,length(vect),replace=TRUE)
  init[[i]] <- list(tau_add=1/var(diff(y.samp)),  ## initial guess on process precision
                    tau_obs=5/var(y.samp))        ## initial guess on obs precision
}
```

### Now that we've defined the model, the data, and the initialization, we need to send all this info to JAGS, which will return the JAGS model object.

```{r}
j.model   <- jags.model (file = textConnection(RandomWalk_Temp),
                             data = data,
                             inits = init,
                             n.chains = 3)
```

### Next, given the defined JAGS model, we'll want to take a few samples from the MCMC chain and assess when the model has converged. To take samples from the MCMC object we'll need to tell JAGS what variables to track and how many samples to take.

```{r, fig.asp = 1.0}
## burn-in
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("tau_add","tau_obs", "beta", "delta"),
                                n.iter = 1000)
plot(jags.out)
```

### Since rjags returns the samples as a CODA object, we can use any of the diagnostics in the R *coda* library to test for convergence, summarize the output, or visualize the chains.

Now that the model has converged we'll want to take a much larger sample from the MCMC and include the full vector of X's in the output

```{r}
jags.out   <- coda.samples (model = j.model,
                            variable.names = c("x","tau_add","tau_obs", "beta0"),
                                n.iter = 10000)
```

### Given the full joint posterior samples, we're next going to visualize the output by just looking at the **95% credible interval of the time-series of X's** and compare that to the observed Y's. To do so we'll convert the coda output into a matrix and then calculate the quantiles. Looking at colnames(out) will show you that the first two columns are `tau_add` and `tau_obs`, so we calculate the CI starting from the 3rd column. We also transform the samples back from the log domain to the linear domain.

```{r}
# THIS CODE DOES NOT WORK -- NEXT CHUNK IS TRYING TO GET THESE SAME PLOTS TO WORK
time.rng = c(1,length(time))       ## adjust to zoom in and out
out <- as.matrix(jags.out)         ## convert from coda to matrix  
x.cols <- grep("^x",colnames(out)) ## grab all columns that start with the letter x
ci <- apply(out[,x.cols], 2, quantile, c(0.025,0.5,0.975)) ## Remove log scale

plot(time,ci[2,],type='n',ylim=range(y,na.rm=TRUE),ylab="Flu Index",log='y',xlim=time[time.rng])
## adjust x-axis label to be monthly if zoomed
if(diff(time.rng) < 100){ 
  axis.Date(1, at=seq(time[time.rng[1]],time[time.rng[2]],by='month'), format = "%Y-%m")
}
ecoforecastR::ciEnvelope(time,ci[1,],ci[3,],col=ecoforecastR::col.alpha("lightBlue",0.75))
points(time,y,pch="+",cex=0.5)
```

### Plotting a reconstruction of the fitted line to the air temp-water temp data

Do this by looping through each iteraction of the MCMC output, each of which has a value for each parameter in your process equation, and making the fitted points by hand.

```{r}
# THIS CODE IS ADAPTED TO PART 3 BUT CAN BE UPDATED FOR THIS    ## adjust to zoom in and out
out <- as.matrix(jags.out)       ## convert from coda to matrix  
N_sim = 10000

# Initialize vectors to store results
x <- numeric(N_sim)
predicted_lake_temp <- numeric(N_sim)

# Loop through each row of the output matrix
for(i in 1:N_sim) {
  beta <- out[i, "beta0[1]"] # extract the value of beta for a given iteration from the output matrix
  delta <- out[i, "beta0[2]"] # extract the value of delta for a given iteration from the output matrix
  x[i] <- out[i, "tau_add"] # extract the estimated latent variable at the previous time step
  predicted_lake_temp[i] <- beta * x[i] + delta * temp
}

str(predicted_lake_temp) # this now had a vector for each iteration and then will need to summarize this to make it work for plotting

library(dplyr)
library(purrr)
# Extract the first element from each vector in predicted_lake_temp and calculate the average
average_values <- numeric(73)

# Loop through each position (1 to 73)
for (i in 1:73) {
  # Extract values at position i from all vectors in predicted_lake_temp
  values <- sapply(predicted_lake_temp, `[`, i)
  # Calculate the average for position i
  average_values[i] <- mean(values, na.rm = TRUE)
}

# Plot the average values
predictedWaterTemp <- plot(average_values, type = "l", col = "blue",
     main = "Average Predicted Lake Temperature",
     xlab = "Time Step", ylab = "Average Temperature")

# Plot each element of predicted_lake_temp -- makes 10000 plots as is
#for (i in 1:length(predicted_lake_temp)) {
#  plot(predicted_lake_temp[[i]], type = "l", col = "blue", ylim = c(-1000, 1000),
#       main = "Predicted Lake Temperature", xlab = "Time Step", ylab = "Temperature")
#}

# Add a legend
#legend("topright", legend = 1:length(predicted_lake_temp), col = "blue", lty = 1, title = "Iteration")

```

###Next, lets look at the posterior distributions for `tau_add` and `tau_obs`, which we'll convert from precisions back into **standard deviations**.

```{r}
hist(1/sqrt(out[,1]),main=colnames(out)[1])
hist(1/sqrt(out[,2]),main=colnames(out)[2])
```

### We'll also want to look at the joint distribution of the two parameters to check whether the two parameters strongly covary.

```{r, fig.asp = 1.0}
plot(out[,1],out[,2],pch=".",xlab=colnames(out)[1],ylab=colnames(out)[2])
cor(out[,1:2])
```
This shows that this doesnt work well since there is a strange relationship with the pond across years that looks more like within year

# Part 5 - Trying to use the Tree Rings and Forest Inventory Example from Alyssa to set this up for the ponds

In this excercise we will extend the state-space framework to combine multipel data streams with different observation errors and to separate observation error from process error. We will also demonstrate how to add hierarchical random effects to partition the process error into multiple sources

Steps that this analysis is divided into here:
1. Load "forest inventory data"
2. Load "tree ring data"
3. Match the tree core and inventory data for individual trees and merge these data sets into one data frame
4. Format this data into a list for input into JAGS
5. Run the JAGS model 
6. Visualize the output

```{r}
library(rjags)
library(ecoforecastR)
```

### This section can be skipped -- but need to sort out how to organize the YF data plots
Steps 1-4 have already been done for you and leverages functions that are part of the [PEcAn system](https://pecanproject.org). Specifically, they are within PEcAn's land data R package, which can be downloaded and installed off Github using `remotes` or `devtools`. Because these steps have been done fore you, you don't need to run the following chunk of code.

```
if(!require(PEcAn.data.land)){
  library(remotes)
  install.packages(c("digest","dplR","PeriodicTable"),repos = "https://cloud.r-project.org")
  remotes::install_github("PecanProject/pecan/base/logger")
  remotes::install_github("PecanProject/pecan/base/remote")
  remotes::install_github("PecanProject/pecan/base/utils")
  remotes::install_github("PecanProject/pecan/base/db")
  remotes::install_github("PecanProject/pecan/modules/data.land")
  library(PEcAn.data.land)
}

## 1. Read tree data
trees <- read.csv("data/H2012AdultFieldData.csv")

## 2. Read tree ring data
rings <- Read_Tucson("data/TUCSON/")

## 3. merge inventory and tree ring data, extract most recent nyears
combined <- matchInventoryRings(trees,rings,nyears=15)

## take a look at the first few rows of data to see the structure
knitr::kable(combined[1:5,])

## 4. organize data into a list
data <- buildJAGSdata_InventoryRings(combined)

## Load in thier 

```
Instead we'll just load and investigate the final, prepared data object

## Check the format here to see how to format the pond temp data
```{r}
load("Activity07.RData")
# y = increment (tree x year)
# z = dbh (tree x year)
# ni = number of individuals
# nt = number of time points
# make sure to take a look at all the priors!
str(data)
knitr::kable(head(data$y))
knitr::kable(head(data$z))
```



















